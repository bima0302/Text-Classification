# -*- coding: utf-8 -*-
"""Text-Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/115lWNuOK4V6uV-k6_8SHzbXUirYdHW-1

# Text Classification Project
## by Abimanyu Sri Setyo

**Project Criteria**
* The dataset to be used is free, but has a minimum of 1000 samples.
* Must use LSTM in model architecture.
* Must use sequential model.
* Validation set is 20% of the total dataset.
* Must use Embedding.
* Must use tokenizer function.
* The accuracy of the model is at least 75% on the train set and validation set.

## Import Dataset
Using data from [Kaggle](https://www.kaggle.com/atulanandjha/imdb-50k-movie-reviews-test-your-bert) and put it into my Google Drive to make it easier to process.
"""

from google.colab import drive
drive.mount('/content/drive/')

import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/Dataset/Movie Reviews/train.csv')

df.head()

"""## Encoding
Change the shape of the data in the sentiment column into a number form for labeling each data.
"""

cat = pd.get_dummies(df.sentiment)
df = pd.concat([df, cat], axis=1)
df = df.drop(columns='sentiment')

df.head()

"""## Split Dataframe
For the model to process, I need to convert the values from the dataframe into the numpy array data type using the values attribute.
"""

review = df['text'].values
label = df[['neg', 'pos']].values

review

label

from sklearn.model_selection import train_test_split

text = df['text'].values
y = df[['pos','neg']].values
text_train , text_test, y_train, y_test = train_test_split(text, y, test_size=0.2)

"""## Tokenizer
Then, I convert every word in our dataset into a numeric number with the Tokenizer function. Once tokenization is complete, I need to make convert each sample into a sequence.
"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=280617, oov_token='-')
tokenizer.fit_on_texts(text_train)
tokenizer.fit_on_texts(text_test)

seq_train = tokenizer.texts_to_sequences(text_train)
seq_test = tokenizer.texts_to_sequences(text_test)

pad_train = pad_sequences(seq_train,
                          maxlen=300,
                          padding='post',
                          truncating='post')

pad_test = pad_sequences(seq_test,
                         maxlen=300,
                         padding='post',
                         truncating='post')

"""## Embedding
For the model architecture, I use the Embedding layer with the embedding dimension of 16, and the input dimension of the num_words value in the tokenizer object.
"""

from tensorflow.keras import layers
from tensorflow.keras import Sequential

model = Sequential([layers.Embedding(280617, 64, input_length=300),
                    layers.LSTM(64, dropout=0.1),
                    layers.Dense(128, activation='relu'),
                    layers.Dense(64, activation='relu'),
                    layers.Dense(2, activation='sigmoid')])
model.summary()

"""## Callback
Then, I created a callback function, its function is to prevent overfitting and stop training after it's done accumulating.
"""

import tensorflow
class myCallback(tensorflow.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.95):
      print("\nAccuracy above 95%, Training Stop!")
      self.model.stop_training = True

callbacks = myCallback()

"""## Training Model
Finally, I can start training our model by calling the fit() function.
"""

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

history = model.fit(pad_train, y_train,
                    batch_size=128,
                    epochs=50,
                    validation_data=(pad_test, y_test),
                    verbose=2,
                    callbacks=[callbacks])

"""## Evaluation Model
I use the matplotlib library to create a plot model to make it easier to evaluate the model that has been created.
"""

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])

plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')

plt.legend(['Train', 'Test'], loc='lower right')
plt.show()